{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b606b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import squeezenet1_1\n",
    "import torch.functional as F\n",
    "from io import open\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a60bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='E:\\\\ml\\\\train'\n",
    "pred_path='E:\\\\ml\\\\predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2bf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df12a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=13):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(in_features=128 * 28 * 28, out_features=512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool1(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.pool2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.pool3(output)\n",
    "\n",
    "        output = output.view(-1, 128 * 28 * 28)\n",
    "\n",
    "        output = self.fc1(output)\n",
    "        output = self.relu4(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu5(output)\n",
    "        output = self.fc3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c1b170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=100352, out_features=512, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (relu5): ReLU()\n",
       "  (fc3): Linear(in_features=256, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint=torch.load('best_checkpoint.model')\n",
    "model=ConvNet(num_classes=13)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9209a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ede655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img_path,data_transforms):\n",
    "    \n",
    "    image=Image.open(img_path)\n",
    "    \n",
    "    image_tensor=data_transforms(image).float()\n",
    "    \n",
    "    image_tensor=image_tensor.unsqueeze_(0)\n",
    "  \n",
    "    input=Variable(image_tensor)\n",
    "    \n",
    "    output=model(input)\n",
    "    \n",
    "    index=output.data.numpy().argmax()\n",
    "    \n",
    "    pred=classes[index]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be34790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path=glob.glob(pred_path+ '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e913341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict={}\n",
    "\n",
    "for i in images_path:\n",
    "    pred_dict[i[i.rfind('/')+1:]] =prediction(i, data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03b03977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E:\\\\ml\\\\predict\\\\p (1).jpg': 'Bulbul',\n",
       " 'E:\\\\ml\\\\predict\\\\p (10).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (100).jpg': 'Penguin',\n",
       " 'E:\\\\ml\\\\predict\\\\p (101).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (102).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (103).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (104).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (105).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (106).jpg': 'Penguin',\n",
       " 'E:\\\\ml\\\\predict\\\\p (107).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (108).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (109).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (11).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (110).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (111).jpg': 'Ostrich',\n",
       " 'E:\\\\ml\\\\predict\\\\p (112).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (113).jpg': 'Peacock',\n",
       " 'E:\\\\ml\\\\predict\\\\p (114).jpg': 'Ostrich',\n",
       " 'E:\\\\ml\\\\predict\\\\p (115).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (116).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (117).jpg': 'Macaw',\n",
       " 'E:\\\\ml\\\\predict\\\\p (118).jpg': 'Macaw',\n",
       " 'E:\\\\ml\\\\predict\\\\p (119).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (12).jpg': 'Penguin',\n",
       " 'E:\\\\ml\\\\predict\\\\p (120).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (121).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (122).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (123).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (124).jpg': 'Bulbul',\n",
       " 'E:\\\\ml\\\\predict\\\\p (125).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (13).jpg': 'Peacock',\n",
       " 'E:\\\\ml\\\\predict\\\\p (14).jpg': 'Ostrich',\n",
       " 'E:\\\\ml\\\\predict\\\\p (15).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (16).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (17).jpg': 'Macaw',\n",
       " 'E:\\\\ml\\\\predict\\\\p (18).jpg': 'Macaw',\n",
       " 'E:\\\\ml\\\\predict\\\\p (19).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (2).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (20).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (21).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (22).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (23).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (24).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (25).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (26).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (27).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (28).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (29).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (3).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (30).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (31).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (32).jpg': 'Kingfisher',\n",
       " 'E:\\\\ml\\\\predict\\\\p (33).jpg': 'Ostrich',\n",
       " 'E:\\\\ml\\\\predict\\\\p (34).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (35).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (36).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (37).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (38).jpg': 'Peacock',\n",
       " 'E:\\\\ml\\\\predict\\\\p (39).jpg': 'Ostrich',\n",
       " 'E:\\\\ml\\\\predict\\\\p (4).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (40).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (41).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (42).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (43).jpg': 'Macaw',\n",
       " 'E:\\\\ml\\\\predict\\\\p (44).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (45).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (46).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (47).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (48).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (49).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (5).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (50).jpg': 'Albatross',\n",
       " 'E:\\\\ml\\\\predict\\\\p (51).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (52).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (53).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (54).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (55).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (56).jpg': 'Penguin',\n",
       " 'E:\\\\ml\\\\predict\\\\p (57).jpg': 'Kingfisher',\n",
       " 'E:\\\\ml\\\\predict\\\\p (58).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (59).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (6).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (60).jpg': 'Penguin',\n",
       " 'E:\\\\ml\\\\predict\\\\p (61).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (62).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (63).jpg': 'Peacock',\n",
       " 'E:\\\\ml\\\\predict\\\\p (64).jpg': 'Ostrich',\n",
       " 'E:\\\\ml\\\\predict\\\\p (65).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (66).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (67).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (68).jpg': 'Penguin',\n",
       " 'E:\\\\ml\\\\predict\\\\p (69).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (7).jpg': 'Kingfisher',\n",
       " 'E:\\\\ml\\\\predict\\\\p (70).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (71).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (72).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (73).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (74).jpg': 'Ostrich',\n",
       " 'E:\\\\ml\\\\predict\\\\p (75).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (76).jpg': 'Hummingbird',\n",
       " 'E:\\\\ml\\\\predict\\\\p (77).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (78).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (79).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (8).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (80).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (81).jpg': 'Penguin',\n",
       " 'E:\\\\ml\\\\predict\\\\p (82).jpg': 'Kingfisher',\n",
       " 'E:\\\\ml\\\\predict\\\\p (83).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (84).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (85).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (86).jpg': 'Bulbul',\n",
       " 'E:\\\\ml\\\\predict\\\\p (87).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (88).jpg': 'Peacock',\n",
       " 'E:\\\\ml\\\\predict\\\\p (89).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (9).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (90).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (91).jpg': 'Dove',\n",
       " 'E:\\\\ml\\\\predict\\\\p (92).jpg': 'Woodpecker',\n",
       " 'E:\\\\ml\\\\predict\\\\p (93).jpg': 'Penguin',\n",
       " 'E:\\\\ml\\\\predict\\\\p (94).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (95).jpg': 'Duck',\n",
       " 'E:\\\\ml\\\\predict\\\\p (96).jpg': 'Owl',\n",
       " 'E:\\\\ml\\\\predict\\\\p (97).jpg': 'Eagle',\n",
       " 'E:\\\\ml\\\\predict\\\\p (98).jpg': 'Ostrich',\n",
       " 'E:\\\\ml\\\\predict\\\\p (99).jpg': 'Dove'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067ac03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
