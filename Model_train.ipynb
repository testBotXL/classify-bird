{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b51688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from PIL import ImageFile\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2baaf370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812f72ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd68a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='E:\\\\ml\\\\train'\n",
    "test_path='E:\\\\ml\\\\test'\n",
    "\n",
    "train_loader= DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=data_transforms),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "test_loader= DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=data_transforms),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81901971",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251e98e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albatross', 'Bulbul', 'Dove', 'Duck', 'Eagle', 'Hummingbird', 'Kingfisher', 'Macaw', 'Ostrich', 'Owl', 'Peacock', 'Penguin', 'Woodpecker']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa9badf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=13):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(in_features=128 * 28 * 28, out_features=512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool1(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.pool2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.pool3(output)\n",
    "\n",
    "        output = output.view(-1, 128 * 28 * 28)\n",
    "\n",
    "        output = self.fc1(output)\n",
    "        output = self.relu4(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu5(output)\n",
    "        output = self.fc3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbf7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= ConvNet(num_classes=13).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "537cd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=Adam(model.parameters(), lr=0.001, weight_decay = 0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4cc0f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf5e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a987d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3970 125\n"
     ]
    }
   ],
   "source": [
    "print(train_count, test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbd86d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(3.8134) Train Accuracy: 0.28463476070528965 Test Accuracy: 0.392\n",
      "Epoch: 1 Train Loss: tensor(1.8208) Train Accuracy: 0.38413098236775817 Test Accuracy: 0.384\n",
      "Epoch: 2 Train Loss: tensor(1.7244) Train Accuracy: 0.4329974811083123 Test Accuracy: 0.472\n",
      "Epoch: 3 Train Loss: tensor(1.6466) Train Accuracy: 0.46574307304785895 Test Accuracy: 0.488\n",
      "Epoch: 4 Train Loss: tensor(1.4900) Train Accuracy: 0.5093198992443325 Test Accuracy: 0.576\n",
      "Epoch: 5 Train Loss: tensor(1.4102) Train Accuracy: 0.5438287153652392 Test Accuracy: 0.512\n",
      "Epoch: 6 Train Loss: tensor(1.3890) Train Accuracy: 0.5546599496221662 Test Accuracy: 0.704\n",
      "Epoch: 7 Train Loss: tensor(1.2803) Train Accuracy: 0.5874055415617129 Test Accuracy: 0.672\n",
      "Epoch: 8 Train Loss: tensor(1.2371) Train Accuracy: 0.5921914357682619 Test Accuracy: 0.584\n",
      "Epoch: 9 Train Loss: tensor(1.1647) Train Accuracy: 0.6244332493702771 Test Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range (num_epochs):\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate (train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate (test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: ' +str(epoch)+ ' Train Loss: ' +str(train_loss)+ ' Train Accuracy: ' +str(train_accuracy)+ ' Test Accuracy: ' +str(test_accuracy))\n",
    "    \n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e88bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
